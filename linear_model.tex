\documentclass[xetex,mathserif,serif]{beamer}
\usepackage{xeCJK}

\usepackage{listings}
\usepackage{hyperref}
\usepackage{algorithmic,algorithm}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{fontspec}
\usepackage{setspace}

\usecolortheme{lily}
\useoutertheme{infolines}
\useinnertheme{rectangles}
\setmainfont{Arial}

\begin{document}
\title[机器学习读书会报告] % (optional, only for long titles)
{读书报告}
\subtitle{第三章 \ 线性模型}
\author{刘精昌 } % (optional, for multiple authors)
\date{\today}
\subject{读书会}

\begin{frame}
\titlepage
\end{frame}

\section{线性回归模型}

\begin{frame}{引例}
  \begin{block}{工资与教育水平关系}
    考查工人工资水平与其受教育关系：
    \begin{itemize}
      \item[a] 工资水平（每小时美元数）：用Y表示
      \item[b] 受教育程度（受教育年数）：用X表示
      \item[c] 非可观测因素，如工作经验、天生素质、工作时间等其他因素
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}{引例}
    \begin{block}{工资与教育水平关系}
    \begin{itemize}
      \item[d] 观测的数据：$\left(x_i,y_i\right),i=1,\cdots,n$ （受访人数）,
    \end{itemize}
    \end{block}

    \begin{center}
    \begin{tabular}{c||c c|c||c c}
      \hline
      % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
      $i$ & $x_i$ & $y_i$ & $i$ & $x_i$ & $y_i$ \\
      \hline
      1 & 5.3 & 1.4 & 9 & 8.5 & 3.2 \\
      2 & 11.0 & 3.9 & 10 & 7.1 & 8.6 \\
      3 & 9 & 6.3 & 11 & 15 & 4 \\
      4 & 8.7 & 8.6 & 12 & 12.0 & 9.0 \\
      5 & 10 & 12 & 13 & 29 & 12 \\
      6 & 15.5 & 12 & 14 & 19.7 & 13.1 \\
      7 & 21 & 16 & 15 & 15.1 & 10 \\
      8 & 19 & 14.4 & 16 & 15.7 & 16 \\
      \hline
    \end{tabular}
    \end{center}

\end{frame}

\begin{frame}{定义}
\[ y_i = \beta_0+x_{i1}\beta_1+ \dots + x_{i,p-1}\beta_{p-1}+e_i, \ i=1,2,\dots,n\]

\[\left( {\begin{array}{*{20}{c}}
{{y_1}}\\
{{y_2}}\\
 \vdots \\
{{y_n}}
\end{array}} \right) = \left( {\begin{array}{*{20}{c}}
1&{{x_{11}}}& \cdots &{{x_{1,p - 1}}}\\
1&{{x_{11}}}& \cdots &{{x_{2,p - 1}}}\\
 \vdots & \vdots &{}& \vdots \\
1&{{x_{11}}}& \cdots &{{x_{n,p - 1}}}
\end{array}} \right)\left( {\begin{array}{*{20}{c}}
{{\omega _0}}\\
{{\omega _1}}\\
 \vdots \\
{{\omega _{p - 1}}}
\end{array}} \right) + \left( {\begin{array}{*{20}{c}}
{{e_1}}\\
{{e_2}}\\
 \vdots \\
{{e_{p - 1}}}
\end{array}} \right)\]

$\bf{y}=\bf{X\beta}+\bf{e}$

\end{frame}

\begin{frame}
\[ y_i = \beta_0+x_{i1}\beta_1+ \dots + x_{i,p-1}\beta_{p-1}+e_i, \ i=1,2,\dots,n\]
\begin{itemize}
  \item[(a)] 拟合值：$\mathop {{y_i}}\limits^ \wedge   = \mathop {{\beta _0}}\limits^ \wedge   + {x_{i1}}\mathop {{\beta _1}}\limits^ \wedge   \cdots  + {x_{i,p - 1}}{{\mathop \beta \limits^ \wedge}  _{p - 1}}$
  \item[(b)] 残差（residual）:${\varepsilon _i} = {y_i} - {{\mathop y\limits^ \wedge}  _i} = {y_i} - \mathop {{\beta _0}}\limits^ \wedge   - {x_{i1}}\mathop {{\beta _1}}\limits^ \wedge   \cdots  + {x_{i,p - 1}}{{\mathop \beta \limits^ \wedge }_{p - 1}}$
  \item[(c)] 残差平方和（residual sum of squares \ RSS）:$RSS \left(\beta\right) = \sum\limits_{i=1}^{n}\varepsilon_i = \sum\limits_{i=1}^{n}\left(y_i - \mathop {{y_i}}\limits^ \wedge\right) = {{{\left( {\mathop y\limits^ \wedge   - X\mathop \beta \limits^ \wedge  } \right)}^T}\left( {\mathop y\limits^ \wedge   - X\mathop \beta \limits^ \wedge  } \right)}$
\end{itemize}
\end{frame}

\begin{frame}{参数求解}
\begin{block}{最小二乘法：RSS最小}
\begin{enumerate}
  \item $E(\mathop \beta \limits^ \wedge) = {\left( {y  - X\mathop \beta \limits^ \wedge  } \right)^T}\left( {y  - X\mathop \beta \limits^ \wedge  } \right) = y^T y - 2 y^T X \mathop \beta \limits^ \wedge + {\mathop \beta \limits^ \wedge} ^T X ^T X \mathop \beta \limits^ \wedge$
  \item $\frac{{\partial E\left( {\mathop \beta \limits^ \wedge  } \right)}}{{\partial \mathop \beta \limits^ \wedge  }} = 0$
  \item $ X^T X \mathop \beta \limits^ \wedge  = X^T y $
  \item $ \mathop \beta \limits^ \wedge = {\left( {{X^T}X} \right)^{ - 1}}{X^T}y $
\end{enumerate}
\end{block}
\end{frame}

\begin{frame}{MLE}
\begin{enumerate}
  \item ${y_i} = {\beta ^T}{x_i} + {e_i},{e_i} \sim N\left( {0,{\sigma ^2}} \right)$
  \item ${y_i} \sim N\left( {{\beta ^T}{x_i},{\sigma ^2}} \right)$
  \item $\mathop \beta \limits^ \wedge   \buildrel \Delta \over = \arg \mathop {\max }\limits_\beta  \log p\left( {D\left| \beta  \right.} \right)$
 \item $l\left( \beta  \right) \buildrel \Delta \over = \log p\left( {D\left| \beta  \right.} \right) 
 = \sum\limits_{i = 1}^n {\log p\left( {{y_i}\left| \beta  \right.} \right)}  
 = \sum\limits_{i = 1}^n {\log \left[ {{{\left( {\frac{1}{{2\pi {\sigma ^2}}}} \right)}^{\frac{1}{2}}}\exp \left( { - \frac{1}{{2{\sigma ^2}}}{{\left( {{y_i} - {\beta ^T}{x_i}} \right)}^2}} \right)} \right]} 
  =  - \frac{1}{{2{\sigma ^2}}}RSS - \frac{N}{2}\log \left( {2\pi {\sigma ^2}} \right)$
\end{enumerate}
\end{frame}

\begin{frame}{平方和的定义}
\begin{itemize}
  \item[a、]总平方和 (Total Sum of Squares \ TSS):
  \begin{center}
    $TSS \buildrel \Delta \over = {\sum\limits_{i = 1}^n {\left( {{y_i} - \overline y } \right)} ^2},\overline y  = \frac{1}{n}\sum\limits_{i = 1}^n {{y_i}} $
  \end{center}
  \item[b、]解释平方和（Explained Sum of Squares \ ESS）:
  \begin{center}
    $ESS \buildrel \Delta \over = {\sum\limits_{i = 1}^n {\left( {{{\mathop y\limits^ \wedge  }_i} - \mathop {\overline y }\limits^ \wedge  } \right)} ^2},\overline {\mathop y\limits^ \wedge  }  = \frac{1}{n}\sum\limits_{i = 1}^n {\mathop {{y_i}}\limits^ \wedge  } $
  \end{center}
\end{itemize}
\end{frame}

\begin{frame}{拟合优度}
\begin{block}{判定系数的定义}
${R^2} = \frac{{ESS}}{{TSS}}$
\end{block}

\begin{block}{判定系数的性质}
\begin{itemize}
  \item $0 \leq R^2 \leq 1$
  \item $R^2$ 越接近1，拟合效果越好
  \item $R^2$ 越接近0，拟合效果越差
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{几何解释}

\end{frame}

\begin{frame}{增加惩罚项}
\begin{block}{ridge regression}
\begin{itemize}
  \item $J\left( \beta  \right) = \frac{1}{n}RSS + \lambda \left\| \beta  \right\|_2^2$
  \item ${\mathop \beta \limits^ \wedge  _{ridge}} = \mathop {\min \arg }\limits_\beta  J\left( \beta  \right)$
  \item ${\mathop \beta \limits^ \wedge  _{ridge}} = {\left( {\lambda I + {X^T}X} \right)^{ - 1}}{X^T}y$
\end{itemize}
\end{block}

\begin{block}{LASSO}
\begin{itemize}
  \item $J\left( \beta  \right) = \frac{1}{n}RSS + \lambda \left\| \beta  \right\|_2^1$
\end{itemize}
\end{block}
\end{frame}

\section{对数几率回归}
\begin{frame}{定义}
\begin{block}
    $p\left( {y\left| {x,w} \right.} \right) = Ber\left( {y\left| {sigm\left( {{w^T}x} \right)} \right.} \right) = \left\{ \begin{array}{l}
    sigm\left( {{w^T}x} \right),y = 1\\
    1 - sigm\left( {{w^T}x} \right),y = 0
    \end{array} \right.$
\end{block}

\begin{block}

\end{block}
\end{frame}

\end{document} 